[dataset]
column=vi
cache_dir=./data/cache
temp_column=comp
data_dir=./data/
extension=.csv
threshold=0.9
n_processes=12
dedup_file=vipubmed_dedup.csv
seed=42
test_size=10000
split_dir=./data/split
train_data=train.csv
val_data=val.csv
test_data=test.csv

[tokenizer]
batch_size=10000
cache_dir=./cache/vipubmed-deberta
column=vi
dataset_dir=./data/cache
min_frequency=5
show_progress=True
vocab_size=128000
pretrained_model_name=Fsoft-AIC/videberta-xsmall

[trainer]
data_seed=42
dataloader_num_workers=4
do_train=True
do_eval=True
evaluation_strategy=steps
eval_steps=5000
fp16=False
gradient_accumulation_steps=4
learning_rate=1e-4
log_level=info
logging_strategy=steps
logging_steps=5000
lr_scheduler_type=linear
mlm_probability=0.15
max_steps=500000
per_device_train_batch_size=16
per_device_eval_batch_size=16
prediction_loss_only=True
report_to=wandb
save_strategy=steps
save_steps=10000
save_total_limit=5
seed=42
warmup_ratio=0.01
warmup_steps=10000
weight_decay=0.015
tokenizer_path=./cache/vipubmed-deberta

[trainer-xsmall]
pretrained_model_name=Fsoft-AIC/videberta-xsmall
max_steps=500000
learning_rate=1e-4
logging_dir=./log/vipubmed-deberta-xsmall/
output_dir=./checkpoint/vipubmed-deberta/xsmall
run_name=vipubmed-deberta-xsmall

[trainer-base]
pretrained_model_name=Fsoft-AIC/videberta-base
max_steps=500000
learning_rate=1e-4
logging_dir=./log/vipubmed-deberta-base/
output_dir=./checkpoint/vipubmed-deberta/base
run_name=vipubmed-deberta-base

[trainer-large]
pretrained_model_name=Fsoft-AIC/videberta-large
max_steps=250000
learning_rate=1e-4
logging_dir=./log/vipubmed-deberta-large/
output_dir=./checkpoint/vipubmed-deberta/large
run_name=vipubmed-deberta-large
save_steps=10000